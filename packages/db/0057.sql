alter table model_mapping add column provider text;

insert into model_mapping (name, pattern, unit, input_cost, output_cost, tokenizer, provider)
values
('granite-3-1-8b-instruct', '^(granite-3-1-8b-instruct)$', 'TOKENS', 0.20, 0.20, 'TODO', 'IBM watsonx.ai'),
('granite-3-1-2b-instruct', '^(granite-3-1-2b-instruct)$', 'TOKENS', 0.10, 0.10, 'TODO', 'IBM watsonx.ai'),
('granite-guardian-3-8b', '^(granite-guardian-3-8b)$', 'TOKENS', 0.20, 0.20, 'TODO', 'IBM watsonx.ai'),
('granite-guardian-3-2b', '^(granite-guardian-3-2b)$', 'TOKENS', 0.10, 0.10, 'TODO', 'IBM watsonx.ai'),
('granite-20b-multilingual', '^(granite-20b-multilingual)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-13b-chat', '^(granite-13b-chat)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-13b-instruct', '^(granite-13b-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-34b-code-instruct', '^(granite-34b-code-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-20b-code-instruct', '^(granite-20b-code-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-8b-code-instruct', '^(granite-8b-code-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-3b-code-instruct', '^(granite-3b-code-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-8b-japanese', '^(granite-8b-japanese)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('granite-7b-lab', '^(granite-7b-lab)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('llama-3-3-70b-instruct', '^(llama-3-3-70b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('llama-3-2-90b-vision-instruct', '^(llama-3-2-90b-vision-instruct)$', 'TOKENS', 2.00, 2.00, 'TODO', 'IBM watsonx.ai'),
('llama-3-2-11b-vision-instruct', '^(llama-3-2-11b-vision-instruct)$', 'TOKENS', 0.35, 0.35, 'TODO', 'IBM watsonx.ai'),
('llama-guard-3-11b-vision', '^(llama-guard-3-11b-vision)$', 'TOKENS', 0.35, 0.35, 'TODO', 'IBM watsonx.ai'),
('llama-3-2-1b-instruct', '^(llama-3-2-1b-instruct)$', 'TOKENS', 0.10, 0.10, 'TODO', 'IBM watsonx.ai'),
('llama-3-2-3b-instruct', '^(llama-3-2-3b-instruct)$', 'TOKENS', 0.15, 0.15, 'TODO', 'IBM watsonx.ai'),
('llama-3-405b-instruct', '^(llama-3-405b-instruct)$', 'TOKENS', 5.00, 16.00, 'TODO', 'IBM watsonx.ai'),
('llama-3-1-70b-instruct', '^(llama-3-1-70b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('llama-3-1-8b-instruct', '^(llama-3-1-8b-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('llama-3-1-8b', '^(llama-3-1-8b)$', 'TOKENS', 0.00, 0.00, 'TODO', 'IBM watsonx.ai'),
('llama3-llava-next-8b-hf', '^(llama3-llava-next-8b-hf)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('llama-3-8b-instruct', '^(llama-3-8b-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('llama-3-70b-instruct', '^(llama-3-70b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('llama2-13b-dpo-v7 (korean)', '^(llama2-13b-dpo-v7 \\(korean\\))$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('allam-1-13b-instruct', '^(allam-1-13b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('codellama-34b-instruct', '^(codellama-34b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('pixtral-12b', '^(pixtral-12b)$', 'TOKENS', 0.35, 0.35, 'TODO', 'IBM watsonx.ai'),
('mistral-large-2', '^(mistral-large-2)$', 'TOKENS', 3.00, 10.00, 'TODO', 'IBM watsonx.ai'),
('mixtral-8x7b-instruct', '^(mixtral-8x7b-instruct)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('jais-13b-chat (arabic)', '^(jais-13b-chat \\(arabic\\))$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('flan-t5-xl-3b', '^(flan-t5-xl-3b)$', 'TOKENS', 0.60, 0.60, 'TODO', 'IBM watsonx.ai'),
('flan-t5-xxl-11b', '^(flan-t5-xxl-11b)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('flan-ul2-20b', '^(flan-ul2-20b)$', 'TOKENS', 5.00, 5.00, 'TODO', 'IBM watsonx.ai'),
('elyza-japanese-llama-2-7b-instruct', '^(elyza-japanese-llama-2-7b-instruct)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai'),
('mt0-xxl-13b', '^(mt0-xxl-13b)$', 'TOKENS', 1.80, 1.80, 'TODO', 'IBM watsonx.ai');